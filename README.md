# Wiki-rnd
Wiki-rnd dataset for small data distributional semantic evaluation (without gold standard), used in the paper "Evaluating the consistency of word embeddings from small data". This dataset contains automatically extracted terms from the index of Quine's Word &amp; Object, and non-overlapping random samples of sentences from a 140M word preprocessed Wikipedia snapshot containing those terms. Split into a training set and a test set by terms.

In the sentences files, the format is one sentence per line. Of a line, the format is: target term, \t, sentence, \n. Within the sentence, the target term is marked with \_\_xxNN, where NN is the number of the sample. For each target term, there are five samples, containing between N/5 and 10 non-overlapping random sentences, where N is the total number of sentences containing the target term.
